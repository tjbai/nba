{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EAST_TEAMS = ['MIL', 'BOS', 'PHI', 'CLE', 'NYK', 'BRK', 'MIA', 'ATL', 'TOR', 'CHI', 'IND', 'WAS', 'ORL', 'CHO', 'DET']\n",
    "WEST_TEAMS = ['DEN', 'MEM', 'SAC', 'PHO', 'LAC', 'GSW', 'LAL', 'MIN', 'NOP', 'OKC', 'DAL', 'UTA', 'POR', 'HOU', 'SAS']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Game Plan\n",
    "\n",
    "- Pages of the format https://www.basketball-reference.com/teams/{TEAM}/{YEAR}_games.html contain\n",
    "an exhaustive schedule of a team's games during the regular season + playoffs\n",
    "\n",
    "- From these pages, we can pull W/L as well as navigate to a page of \n",
    "the format https://www.basketball-reference.com/boxscores/{DATE}{HOME_TEAM}.html\n",
    "where we can pull the officiating team. For this scraping step it's probably most straightforward\n",
    "to find the path value from somewhere inside the main table element, but we could also recreate\n",
    "the date serialization format basketball ref uses and use a dictionary from team names\n",
    "to their shortened \"tickers\".\n",
    "\n",
    "- In general, we may want to create a dictionary corresponding to each team that looks like this:\n",
    "```python\n",
    "{\n",
    "    TEAM: {\n",
    "        'YoY': {\n",
    "            YEAR: {\n",
    "                'W': XX,\n",
    "                'L': XX,\n",
    "                'WLBR': {\n",
    "                    REF_NAME: {\n",
    "                        'W': XX,\n",
    "                        'L': XX\n",
    "                    },\n",
    "                    ...\n",
    "                }\n",
    "            },\n",
    "            ...\n",
    "        },\n",
    "\n",
    "        # Can be calculated at a later step\n",
    "        'Total': {\n",
    "            'W': XX,\n",
    "            'L': XX,\n",
    "            'WLBR': {\n",
    "                REF_NAME:{\n",
    "                    'W': XX,\n",
    "                    'L': XX\n",
    "                },\n",
    "                ...\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    ...\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# More Gameplanning\n",
    "\n",
    "The way this data is structured and the amount of variability in ways we may want to query it almost makes me want to do this all with SQL. I don't know if this makes me blind / an idiot or incredibly smart. In this case, maybe we spin up a local SQL driver? This makes our data collection and structuring process easier and more flexible...\n",
    "\n",
    "In THIS case, we may need to define separate schema for teams, games, and officials.\n",
    "For now, let's avoid tracking data for teams and just run with the team \"tickers\".\n",
    "\n",
    "```sql\n",
    "Game:\n",
    "    id: integer,\n",
    "    good_guys: str,\n",
    "    bad_guys: str,\n",
    "    gg_points: integer,\n",
    "    bg_points: integer,\n",
    "    win: boolean,\n",
    "    date: str\n",
    "\n",
    "Game_Official: \n",
    "    game_id: integer,\n",
    "    official_id: integer\n",
    "\n",
    "Official:\n",
    "    id: integer,\n",
    "    name: str\n",
    "```\n",
    "\n",
    "The other thing to note here is that we're going go to scrape all games from the \"perspective\" \n",
    "of both teams. That means when we're writing queries we need to be careful to not double count.\n",
    "On the other hand, this gives us a nice little invariant to test the robustness of\n",
    "our scraping pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Scraping\n",
    "\n",
    "Okay, now we've setup our sql driver and have all our tables are in a row. We have a slick little DB class that makes use of the `__enter__` and `__exit__` modifiers and some fancy _encapsulation_ going on. Let's run a test scrape on all of the Miami Heat's 2021-22 NBA games and insert them into our local sqlite db."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "TEAM = 'MIA'\n",
    "YEAR = '2022'\n",
    "url = f'https://www.basketball-reference.com/teams/{TEAM}/{YEAR}_games.html'\n",
    "\n",
    "res = requests.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(res.content, 'html.parser')\n",
    "table = soup.find(id='games')\n",
    "\n",
    "for tr in table.tbody:\n",
    "    print(tr)\n",
    "    exit(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Little Obstacle\n",
    "\n",
    "Basketball reference has a 20 request/minute rate limit on their website to prevent scrapers (like me). \n",
    "This is actually really annoying because we need to make a secondary request for every team's\n",
    "game to reach the page containing the officials' names. If we do some math here, scraping ~80 games \n",
    "for 30 teams for even just 10 years means 24,000 requests. Even if we're able to perfectly\n",
    "execute 20 request a minute, this takes 20 hours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "file = open('pickles/MIA_2022.pickle', 'rb')\n",
    "games, officials = pickle.load(file)\n",
    "file.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.10 64-bit ('3.7.10')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4d53f645aae69369cbcc333e2e5ff297875adedaf0a6bdecdb38b897911c43a0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
